
R version 4.4.2 (2024-10-31) -- "Pile of Leaves"
Copyright (C) 2024 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

- Project '~/research/weather-data-collector-spain' loaded. [renv 1.1.4]
> # get_historical_data_expanded.R
> # ----------------------
> # Purpose: Download and update historical daily weather data for Spain from the AEMET OpenData API.
> #
> # This script checks for missing dates in the local historical weather dataset and downloads any missing data in chunks.
> # Data is fetched from the AEMET API, processed, and appended to the local CSV file.
> #
> # Concurrency Control:
> #   - Set PREVENT_CONCURRENT_RUNS = TRUE to enable lockfile-based run prevention
> #   - Set PREVENT_CONCURRENT_RUNS = FALSE (default) to allow multiple concurrent runs
> #
> # Main Steps:
> #   1. Load dependencies and API key.
> #   2. Determine which dates are missing from the local dataset.
> #   3. Download missing data in chunks, handling API rate limits and errors.
> #   4. Append new data to the historical dataset.
> #
> # Usage:
> #   - Requires a valid API key in 'auth/keys.R' as 'my_api_key'.
> #   - Run as an R script. Output is written to 'data/spain_weather_daily_historical.csv.gz'.
> #
> # Dependencies: tidyverse, lubridate, data.table, curl, jsonlite, RSocrata
> #
> # Author: [Your Name]
> # Date: [YYYY-MM-DD]
> 
> # Title ####
> # For downloading and preparing historical weather data. 
> 
> rm(list=ls())
> 
> ####Dependencies####
> library(tidyverse)
── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
✔ dplyr     1.1.4     ✔ readr     2.1.5
✔ forcats   1.0.0     ✔ stringr   1.5.1
✔ ggplot2   3.5.2     ✔ tibble    3.3.0
✔ lubridate 1.9.4     ✔ tidyr     1.3.1
✔ purrr     1.1.0     
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors
> library(lubridate)
> library(data.table)

Attaching package: ‘data.table’

The following objects are masked from ‘package:lubridate’:

    hour, isoweek, mday, minute, month, quarter, second, wday, week,
    yday, year

The following objects are masked from ‘package:dplyr’:

    between, first, last

The following object is masked from ‘package:purrr’:

    transpose

> library(curl)
Using libcurl 8.7.1 with OpenSSL/3.2.2

Attaching package: ‘curl’

The following object is masked from ‘package:readr’:

    parse_date

> library(jsonlite)

Attaching package: ‘jsonlite’

The following object is masked from ‘package:purrr’:

    flatten

> library(RSocrata)
> 
> # If you want to prevent concurrent runs of this script, set PREVENT_CONCURRENT_RUNS to TRUE.
> PREVENT_CONCURRENT_RUNS = FALSE
> 
> if(PREVENT_CONCURRENT_RUNS) {
+   # Prevent concurrent runs by creating a lockfile
+   # Lockfile management
+   lockfile <- "tmp/get_historical_data_expanded.lock"
+   # Check if lockfile exists
+   if (file.exists(lockfile)) {
+     cat("Another run is in progress. Exiting.\n")
+     quit(save = "no", status = 0)
+   }
+   # Create a temporary directory and lockfile
+   dir.create("tmp", showWarnings = FALSE)
+   file.create(lockfile)
+   # Ensure lockfile is removed on exit
+   on.exit(unlink(lockfile), add = TRUE)
+ }
> 
> # Load API keys
> source("auth/keys.R")
> 
> # SETTING DATES ####
> # Set the start date for historical data collection
> start_date = as_date("2013-07-01")
> 
> # Set up curl handle with API key for authentication
> h <- new_handle()
> handle_setheaders(h, 'api_key' = my_api_key)
> 
> # Generate sequence of all dates to check (from start_date to 4 days before today)
> all_dates = seq.Date(from = start_date, to=today()-4, by = "day")
> 
> # Load existing historical weather data
> stored_weather_daily = fread("data/spain_weather_daily_historical.csv.gz")
Error in fread("data/spain_weather_daily_historical.csv.gz") : 
  File 'data/spain_weather_daily_historical.csv.gz' does not exist or is non-readable. getwd()=='/home/j.palmer/research/weather-data-collector-spain'
Calls: fread -> stopf -> raise_condition -> signal
Execution halted
